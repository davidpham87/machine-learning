{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def split_companies_train_dev_test(companies):\n",
    "    \"Return train, dev, test set for companies\"\n",
    "    train, test = train_test_split(companies, test_size=0.1, stratify = companies.sector)\n",
    "    train, dev = train_test_split(train, test_size=0.1, stratify = train.sector)\n",
    "    return train, dev, test\n",
    "\n",
    "\n",
    "def filter_stocks(stocks, tickers):\n",
    "    return stocks.loc[tickers]\n",
    "\n",
    "\n",
    "def df_to_ts(df):\n",
    "    res = df.copy()\n",
    "    res.index = pd.DatetimeIndex(pd.to_datetime(res.date))\n",
    "    res.drop('date', axis=1)\n",
    "    return res\n",
    "\n",
    "\n",
    "def log_softmax(x):\n",
    "    return x - np.log(np.sum(np.exp(x)))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return expit(x)\n",
    "\n",
    "\n",
    "def sample_correlation(df, window_size=63):\n",
    "    idx = np.random.randint(0, df.shape[0]-window_size)\n",
    "    ts = df[idx:idx+window_size]\n",
    "    fmap = lambda s: ts['pct_return'].corr(ts[s])\n",
    "    indices = ts.columns.tolist()[1:]\n",
    "    correlations = np.array(list(map(fmap, indices)))\n",
    "    return correlations\n",
    "\n",
    "\n",
    "def create_correlation_score(df, sample_size=1):\n",
    "    res = np.array([log_softmax(sample_correlation(df)/0.05)\n",
    "                    for i in range(sample_size)])\n",
    "    return np.exp(np.nanmean(res, 0))\n",
    "\n",
    "\n",
    "def load_data(stock_filename=None, indices_filename=None):\n",
    "\n",
    "    if stock_filename is None:\n",
    "        stock_filename = '../../data/processed/wiki_stocks_returns.csv'\n",
    "\n",
    "    if indices_filename is None:\n",
    "        indices_filename = '../../data/processed/wiki_indices_returns.csv'\n",
    "\n",
    "    stocks = pd.read_csv(stock_filename, index_col=False) # long format\n",
    "    indices = pd.read_csv(indices_filename, index_col=False) # wide format\n",
    "\n",
    "    # Implementation of hierarchical clustering\n",
    "    drop_column = lambda df,i=0: df.drop(df.columns[i], axis=1)\n",
    "\n",
    "    stocks = drop_column(stocks)\n",
    "    stocks = stocks.drop('name', axis=1)\n",
    "    stocks = stocks.dropna()\n",
    "\n",
    "    companies = stocks.groupby('ticker').first().reset_index()\n",
    "    sectors_counts = companies.sector.value_counts()\n",
    "    sectors_proportions = sectors_counts/sectors_counts.sum()\n",
    "    sectors_unique = sectors_counts.index.tolist()\n",
    "\n",
    "    stocks = stocks.set_index('ticker')\n",
    "\n",
    "    indices_ts = df_to_ts(indices[['date'] + sectors_unique])\n",
    "    stocks_ts = df_to_ts(stocks.reset_index())\n",
    "\n",
    "    stocks_all = pd.merge(stocks_ts, indices_ts, 'left')\n",
    "    stocks_all = stocks_all.dropna() # loss of 200 000 observations\n",
    "    stocks_all = stocks_all.drop('sector', axis=1)\n",
    "    stocks_all = stocks_all.groupby('ticker').apply(df_to_ts)\n",
    "    stocks_all = stocks_all.drop(['ticker', 'date'], axis=1)\n",
    "    stocks_all = stocks_all.rename(columns={'close': 'pct_return'})\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(sectors_counts.index.tolist())\n",
    "    ticker_to_sector = dict(zip(companies.ticker, label_encoder.transform(companies.sector)))\n",
    "\n",
    "    return stocks_all, companies, label_encoder, ticker_to_sector\n",
    "\n",
    "def sectors_statistics(companies):\n",
    "    sectors_counts = companies.sector.value_counts()\n",
    "    sectors_proportions = sectors_counts/sectors_counts.sum()\n",
    "    sectors_unique = sectors_counts.index.tolist()\n",
    "    return sectors_counts, sectors_proportions, sectors_unique\n",
    "\n",
    "\n",
    "def add_common_layers(y):\n",
    "    y = keras.layers.BatchNormalization()(y)\n",
    "    y = keras.layers.LeakyReLU()(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def grouped_convolution(y, nb_channels, _strides, cardinality=4):\n",
    "    # when `cardinality` == 1 this is just a standard convolution\n",
    "    if cardinality == 1:\n",
    "        return keras.layers.Conv1D(nb_channels, kernel_size=10, strides=_strides, padding='same')(y)\n",
    "\n",
    "    assert not nb_channels % cardinality\n",
    "    _d = nb_channels // cardinality\n",
    "\n",
    "    # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "    # and convolutions are separately performed within each group\n",
    "    groups = []\n",
    "    for j in range(cardinality):\n",
    "        group = keras.layers.Lambda(lambda z: z[:, :, j * _d:j * _d + _d])(y)\n",
    "        groups.append(keras.layers.Conv1D(_d, kernel_size=10, strides=_strides, padding='same')(group))\n",
    "\n",
    "    # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "    y = keras.layers.concatenate(groups)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def residual_block(y, nb_channels_in, nb_channels_out, cardinality=4, _strides=1, _project_shortcut=False):\n",
    "    \"\"\"\n",
    "    Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "    and are subject to two simple rules:\n",
    "    - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "    - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "    \"\"\"\n",
    "    shortcut = y\n",
    "    kl = keras.layers\n",
    "    # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "    y = kl.Conv1D(nb_channels_in, kernel_size=1, strides=1, padding='same')(y)\n",
    "    y = add_common_layers(y)\n",
    "\n",
    "    # ResNeXt (identical to ResNet when `cardinality` == 1)\n",
    "    y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "    y = add_common_layers(y)\n",
    "\n",
    "    y = kl.Conv1D(nb_channels_out, kernel_size=1, strides=1, padding='same')(y)\n",
    "    # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "    y = kl.BatchNormalization()(y)\n",
    "\n",
    "    # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "    if _project_shortcut or _strides != 1:\n",
    "        # when the dimensions increase projection shortcut is used to match dimensions (done by 1Ã—1 convolutions)\n",
    "        # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "        shortcut = kl.Conv1D(nb_channels_out, kernel_size=1, strides=_strides, padding='same')(shortcut)\n",
    "        shortcut = kl.BatchNormalization()(shortcut)\n",
    "\n",
    "    y = kl.add([shortcut, y])\n",
    "\n",
    "    # relu is performed right after each batch normalization,\n",
    "    # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "    y = kl.LeakyReLU()(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = keras.backend.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = tf.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class CovarianceLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        self.num_classes = num_classes\n",
    "        super(CovarianceLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        super(CovarianceLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        series_input, environment_input = inputs\n",
    "        series_input_multiple = tf.tile(series_input, [1, 1, self.num_classes])\n",
    "        covariances = tf.reduce_mean(series_input_multiple * environment_input, axis=1)\n",
    "        \n",
    "        return covariances\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "\n",
    "def random_subset(df, window_size=21):\n",
    "    idx = np.random.randint(0, df.shape[0]-window_size)\n",
    "    ts = df[idx:idx+window_size]\n",
    "    return ts\n",
    "\n",
    "\n",
    "def make_keras_subset(dataset_type, companies_data, stocks_data, label_encoder, batch_size, window_size=21):\n",
    "    idx = np.random.choice(companies_data[dataset_type].shape[0], batch_size)\n",
    "    df = companies_data[dataset_type].iloc[idx]\n",
    "\n",
    "    model_input_data = [random_subset(stocks_data[dataset_type].loc[t], window_size) for t in df.ticker]\n",
    "    model_series_input = np.array([df['pct_return'].values for df in model_input_data])\n",
    "    model_series_input = model_series_input.reshape(-1, window_size, 1)\n",
    "\n",
    "    model_environment_input = np.array([df.iloc[:, 1:].values for df in model_input_data])\n",
    "\n",
    "    y_true = label_encoder.transform(df.sector)\n",
    "\n",
    "    return model_series_input, model_environment_input, y_true\n",
    "\n",
    "\n",
    "class StocksSequence(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, stocks_data,  companies_data, window_size, label_encoder, batch_size):\n",
    "        self.stocks_data = stocks_data\n",
    "        self.batch_size = batch_size\n",
    "        self.label_encoder = label_encoder\n",
    "        self.companies_data = companies_data\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.stocks_data.shape[0] / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx = np.random.choice(self.companies_data.shape[0], self.batch_size)\n",
    "        df = self.companies_data.iloc[idx]\n",
    "        model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
    "        model_series_input = np.array([df['pct_return'].values for df in model_input_data])\n",
    "        model_series_input = model_series_input.reshape(-1, self.window_size, 1)\n",
    "        model_environment_input = np.array([df.iloc[:, 1:].values for df in model_input_data])\n",
    "        y_true = self.label_encoder.transform(df.sector)\n",
    "\n",
    "        return [model_series_input, model_environment_input], y_true\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covariance_convolution_weight(shape, dtype=None):\n",
    "    kernel_shape = shape[0]\n",
    "    num_classes = shape[1]\n",
    "    filters = shape[2]\n",
    "    x = np.zeros([kernel_shape, num_classes, filters])\n",
    "    noise = np.random.normal(0, 0.001, size=[kernel_shape, num_classes, filters])\n",
    "\n",
    "    for j in range(0, filters):\n",
    "        j_class = j % num_classes\n",
    "        x[:, [0, j_class], j] = 1\n",
    "    return x + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(num_classes=16, window_size=21, latent_dim=32):\n",
    "    kl = keras.layers\n",
    "    \n",
    "    series_input = keras.layers.Input(shape=(window_size, 1), dtype='float32', name='series_input')\n",
    "    environment_input = kl.Input(shape=(window_size, num_classes), dtype='float32', name='environment_input')\n",
    "    x = kl.Concatenate()([series_input, environment_input])\n",
    "    x = kl.GaussianNoise(0.001)(x)  \n",
    "    x = kl.AveragePooling1D(2,1)(x)\n",
    "    tanh_layer = kl.Lambda(lambda y: tf.tanh(tf.scalar_mul(3, y))) \n",
    "    x = tanh_layer(x)    \n",
    "    x = kl.Conv1D(32, 5, 1, activation='relu', \n",
    "                  kernel_initializer=keras.initializers.Orthogonal())(x)  \n",
    "    x = kl.Conv1D(64, 5, 3, activation='relu',\n",
    "                  kernel_initializer=keras.initializers.Orthogonal())(x)\n",
    "    x = kl.Conv1D(128, 3, 2, activation='relu',\n",
    "                  kernel_initializer=keras.initializers.Orthogonal()))(x)\n",
    "    # x = kl.Conv1D(32, 5, 2, activation='relu')(x)\n",
    "    x = kl.Flatten(name='Embedding')(x)\n",
    "    x_pred = kl.Dense(num_classes, 'sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs = [series_input, environment_input], outputs=[x_pred], name='Classifier')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most representated class: Financial Services , with proportion of  13.09 %.\n"
     ]
    }
   ],
   "source": [
    "# Make train dev test set.\n",
    "np.random.seed(42)\n",
    "\n",
    "### Feature engineering\n",
    "\n",
    "stock_filename = '../data/processed/wiki_stocks_returns.csv'\n",
    "indices_filename = '../data/processed/wiki_indices_returns.csv'\n",
    "\n",
    "stocks_all, companies, label_encoder, ticker_to_sector = load_data(stock_filename, indices_filename)\n",
    "sectors_counts, sectors_proportions, sectors_unique = sectors_statistics(companies)\n",
    "\n",
    "max_proportion_baseline = sectors_proportions.max()\n",
    "biggest_sector = sectors_proportions.argmax()\n",
    "\n",
    "print(\"Most representated class:\", biggest_sector, ', with proportion of ', round(100*max_proportion_baseline, 2), '%.')\n",
    "# Accuracy of our models should be better than max_proportion_baseline.\n",
    "\n",
    "companies_data = {}\n",
    "data_split = split_companies_train_dev_test(companies)\n",
    "for i, k in enumerate(['train', 'dev', 'test']):\n",
    "    companies_data[k] = data_split[i]\n",
    "stocks_data = {k: filter_stocks(stocks_all, v.ticker) for k, v in companies_data.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 63\n",
    "model = make_model(window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model.load_weights('checkpoint/model_weights_third.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def schedule_fn(epoch):\n",
    "   initial_lrate = 0.001\n",
    "   drop = 0.8\n",
    "   epochs_drop = 10.0\n",
    "   lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "series_input (InputLayer)       (None, 63, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "environment_input (InputLayer)  (None, 63, 16)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 63, 17)       0           series_input[0][0]               \n",
      "                                                                 environment_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNoise (None, 63, 17)       0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_9 (AveragePoo (None, 62, 17)       0           gaussian_noise_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 62, 17)       0           average_pooling1d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 58, 32)       2752        lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 18, 64)       10304       conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 8, 128)       24704       conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Embedding (Flatten)             (None, 1024)         0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16)           16400       Embedding[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 54,160\n",
      "Trainable params: 54,160\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('checkpoint/model_weights_fourth.json', monitor='val_acc', verbose=1, save_best_only=True, mode='max'),\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs/twelveth'),\n",
    "    keras.callbacks.LearningRateScheduler(schedule_fn)\n",
    "]\n",
    "\n",
    "stocks_sequence_training = StocksSequence(stocks_data['train'], companies_data['train'], window_size, label_encoder, batch_size)\n",
    "stocks_sequence_validation = StocksSequence(stocks_data['dev'], companies_data['dev'], window_size, label_encoder, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 2.5011 - acc: 0.1910Epoch 00001: val_acc improved from -inf to 0.25406, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 2.5008 - acc: 0.1911 - val_loss: 2.3949 - val_acc: 0.2541\n",
      "\n",
      "Epoch 2/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 2.1815 - acc: 0.3124Epoch 00002: val_acc improved from 0.25406 to 0.32219, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 2.1812 - acc: 0.3126 - val_loss: 2.2170 - val_acc: 0.3222\n",
      "\n",
      "Epoch 3/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 2.0398 - acc: 0.3606Epoch 00003: val_acc improved from 0.32219 to 0.35207, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 2.0397 - acc: 0.3607 - val_loss: 2.1107 - val_acc: 0.3521\n",
      "\n",
      "Epoch 4/400\n",
      " 996/1000 [============================>.] 996/1000 [============================>.] - ETA: 0s - loss: 1.9810 - acc: 0.3812Epoch 00004: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.9808 - acc: 0.3813 - val_loss: 2.1307 - val_acc: 0.3503\n",
      "\n",
      "Epoch 5/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.9266 - acc: 0.3951Epoch 00005: val_acc improved from 0.35207 to 0.36625, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.9266 - acc: 0.3952 - val_loss: 2.0356 - val_acc: 0.3663\n",
      "\n",
      "Epoch 6/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.8851 - acc: 0.4047Epoch 00006: val_acc improved from 0.36625 to 0.37625, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.8852 - acc: 0.4046 - val_loss: 2.0052 - val_acc: 0.3762\n",
      "\n",
      "Epoch 7/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.8586 - acc: 0.4138Epoch 00007: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.8586 - acc: 0.4138 - val_loss: 1.9974 - val_acc: 0.3720\n",
      "\n",
      "Epoch 8/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.8414 - acc: 0.4176Epoch 00008: val_acc improved from 0.37625 to 0.38578, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.8415 - acc: 0.4176 - val_loss: 1.9807 - val_acc: 0.3858\n",
      "\n",
      "Epoch 9/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.8176 - acc: 0.4234Epoch 00009: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.8176 - acc: 0.4234 - val_loss: 1.9757 - val_acc: 0.3770\n",
      "\n",
      "Epoch 10/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.7972 - acc: 0.4294Epoch 00010: val_acc improved from 0.38578 to 0.39035, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.7972 - acc: 0.4294 - val_loss: 1.9563 - val_acc: 0.3904\n",
      "\n",
      "Epoch 11/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.7918 - acc: 0.4324Epoch 00011: val_acc improved from 0.39035 to 0.39102, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.7917 - acc: 0.4324 - val_loss: 1.9492 - val_acc: 0.3910\n",
      "\n",
      "Epoch 12/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.7797 - acc: 0.4367Epoch 00012: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.7796 - acc: 0.4367 - val_loss: 1.9538 - val_acc: 0.3881\n",
      "\n",
      "Epoch 13/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.7465 - acc: 0.4473Epoch 00013: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.7465 - acc: 0.4473 - val_loss: 1.9676 - val_acc: 0.3820\n",
      "\n",
      "Epoch 14/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.7549 - acc: 0.4449Epoch 00014: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.7548 - acc: 0.4449 - val_loss: 1.9550 - val_acc: 0.3903\n",
      "\n",
      "Epoch 15/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.7101 - acc: 0.4569Epoch 00015: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.7100 - acc: 0.4569 - val_loss: 1.9352 - val_acc: 0.3900\n",
      "\n",
      "Epoch 16/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.7146 - acc: 0.4551Epoch 00016: val_acc improved from 0.39102 to 0.40672, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.7145 - acc: 0.4551 - val_loss: 1.8736 - val_acc: 0.4067\n",
      "\n",
      "Epoch 17/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6885 - acc: 0.4649Epoch 00017: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.6884 - acc: 0.4649 - val_loss: 1.9124 - val_acc: 0.3972\n",
      "\n",
      "Epoch 18/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6735 - acc: 0.4687Epoch 00018: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.6734 - acc: 0.4687 - val_loss: 1.8997 - val_acc: 0.4019\n",
      "\n",
      "Epoch 19/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6667 - acc: 0.4703Epoch 00019: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.6668 - acc: 0.4702 - val_loss: 1.8752 - val_acc: 0.4031\n",
      "\n",
      "Epoch 20/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6761 - acc: 0.4688Epoch 00020: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.6761 - acc: 0.4688 - val_loss: 1.8850 - val_acc: 0.4056\n",
      "\n",
      "Epoch 21/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6693 - acc: 0.4677Epoch 00021: val_acc improved from 0.40672 to 0.40922, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.6693 - acc: 0.4678 - val_loss: 1.8826 - val_acc: 0.4092\n",
      "\n",
      "Epoch 22/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.6301 - acc: 0.4820Epoch 00022: val_acc improved from 0.40922 to 0.41031, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.6302 - acc: 0.4820 - val_loss: 1.8770 - val_acc: 0.4103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6317 - acc: 0.4813Epoch 00023: val_acc improved from 0.41031 to 0.41719, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.6317 - acc: 0.4814 - val_loss: 1.8617 - val_acc: 0.4172\n",
      "\n",
      "Epoch 24/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6200 - acc: 0.4848Epoch 00024: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.6200 - acc: 0.4848 - val_loss: 1.8919 - val_acc: 0.4116\n",
      "\n",
      "Epoch 25/400\n",
      " 996/1000 [============================>.] 996/1000 [============================>.] - ETA: 0s - loss: 1.6161 - acc: 0.4872Epoch 00025: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.6158 - acc: 0.4872 - val_loss: 1.8617 - val_acc: 0.4142\n",
      "\n",
      "Epoch 26/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.6165 - acc: 0.4878Epoch 00026: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.6165 - acc: 0.4879 - val_loss: 1.8928 - val_acc: 0.4066\n",
      "\n",
      "Epoch 27/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.6335 - acc: 0.4822Epoch 00027: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.6334 - acc: 0.4822 - val_loss: 1.8688 - val_acc: 0.4161\n",
      "\n",
      "Epoch 28/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.6203 - acc: 0.4853Epoch 00028: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.6204 - acc: 0.4853 - val_loss: 1.8631 - val_acc: 0.4131\n",
      "\n",
      "Epoch 29/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.6160 - acc: 0.4870Epoch 00029: val_acc improved from 0.41719 to 0.42156, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.6160 - acc: 0.4870 - val_loss: 1.8525 - val_acc: 0.4216\n",
      "\n",
      "Epoch 30/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5979 - acc: 0.4928Epoch 00030: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5979 - acc: 0.4928 - val_loss: 1.8569 - val_acc: 0.4142\n",
      "\n",
      "Epoch 31/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5887 - acc: 0.4941Epoch 00031: val_acc improved from 0.42156 to 0.42402, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5887 - acc: 0.4941 - val_loss: 1.8350 - val_acc: 0.4240\n",
      "\n",
      "Epoch 32/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5878 - acc: 0.4955Epoch 00032: val_acc improved from 0.42402 to 0.43109, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5879 - acc: 0.4955 - val_loss: 1.8225 - val_acc: 0.4311\n",
      "\n",
      "Epoch 33/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5852 - acc: 0.4977Epoch 00033: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5852 - acc: 0.4977 - val_loss: 1.8626 - val_acc: 0.4222\n",
      "\n",
      "Epoch 34/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5812 - acc: 0.4971Epoch 00034: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5810 - acc: 0.4972 - val_loss: 1.8292 - val_acc: 0.4288\n",
      "\n",
      "Epoch 35/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.5538 - acc: 0.5059Epoch 00035: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5539 - acc: 0.5058 - val_loss: 1.8465 - val_acc: 0.4181\n",
      "\n",
      "Epoch 36/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.5722 - acc: 0.5003Epoch 00036: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 118s 118ms/step - loss: 1.5724 - acc: 0.5002 - val_loss: 1.8284 - val_acc: 0.4213\n",
      "\n",
      "Epoch 37/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5603 - acc: 0.5046Epoch 00037: val_acc improved from 0.43109 to 0.43262, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.5602 - acc: 0.5047 - val_loss: 1.8217 - val_acc: 0.4326\n",
      "\n",
      "Epoch 38/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5566 - acc: 0.5062Epoch 00038: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.5565 - acc: 0.5062 - val_loss: 1.8614 - val_acc: 0.4220\n",
      "\n",
      "Epoch 39/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5613 - acc: 0.5052Epoch 00039: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.5613 - acc: 0.5053 - val_loss: 1.8653 - val_acc: 0.4144\n",
      "\n",
      "Epoch 40/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5694 - acc: 0.5023Epoch 00040: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5694 - acc: 0.5023 - val_loss: 1.8284 - val_acc: 0.4325\n",
      "\n",
      "Epoch 41/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5509 - acc: 0.5079Epoch 00041: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5511 - acc: 0.5079 - val_loss: 1.8735 - val_acc: 0.4261\n",
      "\n",
      "Epoch 42/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5690 - acc: 0.5015Epoch 00042: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5690 - acc: 0.5016 - val_loss: 1.8633 - val_acc: 0.4321\n",
      "\n",
      "Epoch 43/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5549 - acc: 0.5057Epoch 00043: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5547 - acc: 0.5058 - val_loss: 1.8205 - val_acc: 0.4286\n",
      "\n",
      "Epoch 44/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5381 - acc: 0.5109Epoch 00044: val_acc improved from 0.43262 to 0.43695, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.5381 - acc: 0.5109 - val_loss: 1.8004 - val_acc: 0.4370\n",
      "\n",
      "Epoch 45/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.5394 - acc: 0.5119Epoch 00045: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5396 - acc: 0.5119 - val_loss: 1.8266 - val_acc: 0.4232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5399 - acc: 0.5122Epoch 00046: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5399 - acc: 0.5122 - val_loss: 1.8381 - val_acc: 0.4292\n",
      "\n",
      "Epoch 47/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5398 - acc: 0.5111Epoch 00047: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5397 - acc: 0.5111 - val_loss: 1.8292 - val_acc: 0.4314\n",
      "\n",
      "Epoch 48/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.5264 - acc: 0.5142Epoch 00048: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.5266 - acc: 0.5142 - val_loss: 1.8251 - val_acc: 0.4340\n",
      "\n",
      "Epoch 49/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5300 - acc: 0.5141Epoch 00049: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.5299 - acc: 0.5141 - val_loss: 1.8338 - val_acc: 0.4297\n",
      "\n",
      "Epoch 50/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5178 - acc: 0.5182Epoch 00050: val_acc improved from 0.43695 to 0.44250, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5178 - acc: 0.5182 - val_loss: 1.7958 - val_acc: 0.4425\n",
      "\n",
      "Epoch 51/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.5211 - acc: 0.5183Epoch 00051: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.5212 - acc: 0.5182 - val_loss: 1.8171 - val_acc: 0.4370\n",
      "\n",
      "Epoch 52/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5182 - acc: 0.5194Epoch 00052: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.5182 - acc: 0.5194 - val_loss: 1.8099 - val_acc: 0.4380\n",
      "\n",
      "Epoch 53/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.5264 - acc: 0.5164Epoch 00053: val_acc improved from 0.44250 to 0.44438, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.5264 - acc: 0.5164 - val_loss: 1.8140 - val_acc: 0.4444\n",
      "\n",
      "Epoch 54/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5095 - acc: 0.5214Epoch 00054: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.5095 - acc: 0.5214 - val_loss: 1.8290 - val_acc: 0.4372\n",
      "\n",
      "Epoch 55/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5221 - acc: 0.5187Epoch 00055: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5222 - acc: 0.5186 - val_loss: 1.7952 - val_acc: 0.4389\n",
      "\n",
      "Epoch 56/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5188 - acc: 0.5186Epoch 00056: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5187 - acc: 0.5186 - val_loss: 1.8183 - val_acc: 0.4339\n",
      "\n",
      "Epoch 57/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5017 - acc: 0.5230Epoch 00057: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5018 - acc: 0.5230 - val_loss: 1.8412 - val_acc: 0.4293\n",
      "\n",
      "Epoch 58/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5097 - acc: 0.5216Epoch 00058: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5098 - acc: 0.5216 - val_loss: 1.7992 - val_acc: 0.4380\n",
      "\n",
      "Epoch 59/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5026 - acc: 0.5252Epoch 00059: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5025 - acc: 0.5252 - val_loss: 1.8165 - val_acc: 0.4373\n",
      "\n",
      "Epoch 60/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5029 - acc: 0.5227Epoch 00060: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5029 - acc: 0.5227 - val_loss: 1.8201 - val_acc: 0.4431\n",
      "\n",
      "Epoch 61/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4933 - acc: 0.5258Epoch 00061: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4932 - acc: 0.5258 - val_loss: 1.8164 - val_acc: 0.4341\n",
      "\n",
      "Epoch 62/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5095 - acc: 0.5213Epoch 00062: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5096 - acc: 0.5213 - val_loss: 1.8241 - val_acc: 0.4397\n",
      "\n",
      "Epoch 63/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4902 - acc: 0.5283Epoch 00063: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4901 - acc: 0.5284 - val_loss: 1.8075 - val_acc: 0.4406\n",
      "\n",
      "Epoch 64/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4898 - acc: 0.5291Epoch 00064: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4898 - acc: 0.5291 - val_loss: 1.8130 - val_acc: 0.4363\n",
      "\n",
      "Epoch 65/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4973 - acc: 0.5255Epoch 00065: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4975 - acc: 0.5255 - val_loss: 1.8116 - val_acc: 0.4427\n",
      "\n",
      "Epoch 66/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.5024 - acc: 0.5239Epoch 00066: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.5023 - acc: 0.5239 - val_loss: 1.8082 - val_acc: 0.4420\n",
      "\n",
      "Epoch 67/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4875 - acc: 0.5295Epoch 00067: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4874 - acc: 0.5295 - val_loss: 1.8183 - val_acc: 0.4381\n",
      "\n",
      "Epoch 68/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4891 - acc: 0.5300Epoch 00068: val_acc improved from 0.44438 to 0.44875, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4891 - acc: 0.5301 - val_loss: 1.8048 - val_acc: 0.4487\n",
      "\n",
      "Epoch 69/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4931 - acc: 0.5260Epoch 00069: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4930 - acc: 0.5260 - val_loss: 1.7904 - val_acc: 0.4417\n",
      "\n",
      "Epoch 70/400\n",
      " 996/1000 [============================>.] 996/1000 [============================>.] - ETA: 0s - loss: 1.4841 - acc: 0.5286Epoch 00070: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4839 - acc: 0.5286 - val_loss: 1.7970 - val_acc: 0.4483\n",
      "\n",
      "Epoch 71/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.5113 - acc: 0.5205Epoch 00071: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.5111 - acc: 0.5206 - val_loss: 1.8101 - val_acc: 0.4414\n",
      "\n",
      "Epoch 72/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4929 - acc: 0.5280Epoch 00072: val_acc improved from 0.44875 to 0.44984, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4929 - acc: 0.5280 - val_loss: 1.7976 - val_acc: 0.4498\n",
      "\n",
      "Epoch 73/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4847 - acc: 0.5286Epoch 00073: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4848 - acc: 0.5286 - val_loss: 1.8180 - val_acc: 0.4386\n",
      "\n",
      "Epoch 74/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4808 - acc: 0.5317Epoch 00074: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4808 - acc: 0.5316 - val_loss: 1.7980 - val_acc: 0.4419\n",
      "\n",
      "Epoch 75/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4808 - acc: 0.5313Epoch 00075: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4808 - acc: 0.5313 - val_loss: 1.7883 - val_acc: 0.4494\n",
      "\n",
      "Epoch 76/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4660 - acc: 0.5362Epoch 00076: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4660 - acc: 0.5362 - val_loss: 1.8096 - val_acc: 0.4464\n",
      "\n",
      "Epoch 77/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4700 - acc: 0.5356Epoch 00077: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4699 - acc: 0.5356 - val_loss: 1.8104 - val_acc: 0.4424\n",
      "\n",
      "Epoch 78/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4770 - acc: 0.5329Epoch 00078: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4770 - acc: 0.5329 - val_loss: 1.8068 - val_acc: 0.4458\n",
      "\n",
      "Epoch 79/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4755 - acc: 0.5327Epoch 00079: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4756 - acc: 0.5326 - val_loss: 1.8104 - val_acc: 0.4425\n",
      "\n",
      "Epoch 80/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4699 - acc: 0.5342Epoch 00080: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4700 - acc: 0.5342 - val_loss: 1.7975 - val_acc: 0.4480\n",
      "\n",
      "Epoch 81/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4726 - acc: 0.5367Epoch 00081: val_acc improved from 0.44984 to 0.45027, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4726 - acc: 0.5367 - val_loss: 1.7922 - val_acc: 0.4503\n",
      "\n",
      "Epoch 82/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4706 - acc: 0.5345Epoch 00082: val_acc improved from 0.45027 to 0.45031, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4705 - acc: 0.5345 - val_loss: 1.7773 - val_acc: 0.4503\n",
      "\n",
      "Epoch 83/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4651 - acc: 0.5351Epoch 00083: val_acc improved from 0.45031 to 0.45656, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4651 - acc: 0.5351 - val_loss: 1.7808 - val_acc: 0.4566\n",
      "\n",
      "Epoch 84/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4782 - acc: 0.5320Epoch 00084: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4782 - acc: 0.5320 - val_loss: 1.7998 - val_acc: 0.4431\n",
      "\n",
      "Epoch 85/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4685 - acc: 0.5365Epoch 00085: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4685 - acc: 0.5365 - val_loss: 1.7917 - val_acc: 0.4478\n",
      "\n",
      "Epoch 86/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4684 - acc: 0.5344Epoch 00086: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4685 - acc: 0.5344 - val_loss: 1.8049 - val_acc: 0.4456\n",
      "\n",
      "Epoch 87/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4599 - acc: 0.5381Epoch 00087: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4598 - acc: 0.5381 - val_loss: 1.7788 - val_acc: 0.4545\n",
      "\n",
      "Epoch 88/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4650 - acc: 0.5364Epoch 00088: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4649 - acc: 0.5364 - val_loss: 1.8221 - val_acc: 0.4402\n",
      "\n",
      "Epoch 89/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4504 - acc: 0.5416Epoch 00089: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4505 - acc: 0.5416 - val_loss: 1.7901 - val_acc: 0.4467\n",
      "\n",
      "Epoch 90/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4544 - acc: 0.5403Epoch 00090: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4545 - acc: 0.5403 - val_loss: 1.8096 - val_acc: 0.4431\n",
      "\n",
      "Epoch 91/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4607 - acc: 0.5388Epoch 00091: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4608 - acc: 0.5388 - val_loss: 1.7940 - val_acc: 0.4453\n",
      "\n",
      "Epoch 92/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4563 - acc: 0.5392Epoch 00092: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4562 - acc: 0.5392 - val_loss: 1.7801 - val_acc: 0.4525\n",
      "\n",
      "Epoch 93/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4545 - acc: 0.5391Epoch 00093: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4544 - acc: 0.5391 - val_loss: 1.7823 - val_acc: 0.4528\n",
      "\n",
      "Epoch 94/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4570 - acc: 0.5407Epoch 00094: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4570 - acc: 0.5407 - val_loss: 1.7875 - val_acc: 0.4497\n",
      "\n",
      "Epoch 95/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4570 - acc: 0.5392Epoch 00095: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4570 - acc: 0.5392 - val_loss: 1.7787 - val_acc: 0.4506\n",
      "\n",
      "Epoch 96/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4589 - acc: 0.5375Epoch 00096: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4590 - acc: 0.5374 - val_loss: 1.7776 - val_acc: 0.4491\n",
      "\n",
      "Epoch 97/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4616 - acc: 0.5378Epoch 00097: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4614 - acc: 0.5379 - val_loss: 1.7817 - val_acc: 0.4536\n",
      "\n",
      "Epoch 98/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4534 - acc: 0.5417Epoch 00098: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4535 - acc: 0.5417 - val_loss: 1.7840 - val_acc: 0.4541\n",
      "\n",
      "Epoch 99/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4535 - acc: 0.5386Epoch 00099: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4534 - acc: 0.5386 - val_loss: 1.7993 - val_acc: 0.4493\n",
      "\n",
      "Epoch 100/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4558 - acc: 0.5388Epoch 00100: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4557 - acc: 0.5388 - val_loss: 1.7862 - val_acc: 0.4502\n",
      "\n",
      "Epoch 101/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4555 - acc: 0.5395Epoch 00101: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4558 - acc: 0.5394 - val_loss: 1.7796 - val_acc: 0.4487\n",
      "\n",
      "Epoch 102/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4468 - acc: 0.5432Epoch 00102: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4469 - acc: 0.5431 - val_loss: 1.7868 - val_acc: 0.4509\n",
      "\n",
      "Epoch 103/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4411 - acc: 0.5450Epoch 00103: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4412 - acc: 0.5449 - val_loss: 1.8061 - val_acc: 0.4444\n",
      "\n",
      "Epoch 104/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4650 - acc: 0.5369Epoch 00104: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4649 - acc: 0.5369 - val_loss: 1.7938 - val_acc: 0.4528\n",
      "\n",
      "Epoch 105/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4530 - acc: 0.5395Epoch 00105: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4530 - acc: 0.5395 - val_loss: 1.7915 - val_acc: 0.4494\n",
      "\n",
      "Epoch 106/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4536 - acc: 0.5405Epoch 00106: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4534 - acc: 0.5406 - val_loss: 1.8114 - val_acc: 0.4477\n",
      "\n",
      "Epoch 107/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4543 - acc: 0.5421Epoch 00107: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4544 - acc: 0.5420 - val_loss: 1.8042 - val_acc: 0.4502\n",
      "\n",
      "Epoch 108/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4600 - acc: 0.5370Epoch 00108: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4600 - acc: 0.5370 - val_loss: 1.7900 - val_acc: 0.4475\n",
      "\n",
      "Epoch 109/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4487 - acc: 0.5413Epoch 00109: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4488 - acc: 0.5412 - val_loss: 1.7861 - val_acc: 0.4478\n",
      "\n",
      "Epoch 110/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4519 - acc: 0.5410Epoch 00110: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4518 - acc: 0.5410 - val_loss: 1.7897 - val_acc: 0.4514\n",
      "\n",
      "Epoch 111/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4494 - acc: 0.5426Epoch 00111: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4494 - acc: 0.5426 - val_loss: 1.7823 - val_acc: 0.4537\n",
      "\n",
      "Epoch 112/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4434 - acc: 0.5423Epoch 00112: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4435 - acc: 0.5423 - val_loss: 1.7965 - val_acc: 0.4453\n",
      "\n",
      "Epoch 113/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4503 - acc: 0.5432Epoch 00113: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4502 - acc: 0.5432 - val_loss: 1.7989 - val_acc: 0.4512\n",
      "\n",
      "Epoch 114/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4440 - acc: 0.5430Epoch 00114: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4439 - acc: 0.5430 - val_loss: 1.7830 - val_acc: 0.4522\n",
      "\n",
      "Epoch 115/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4416 - acc: 0.5447Epoch 00115: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4416 - acc: 0.5447 - val_loss: 1.7921 - val_acc: 0.4520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 116/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4341 - acc: 0.5467Epoch 00116: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4341 - acc: 0.5467 - val_loss: 1.8149 - val_acc: 0.4436\n",
      "\n",
      "Epoch 117/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4492 - acc: 0.5427Epoch 00117: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4490 - acc: 0.5428 - val_loss: 1.7883 - val_acc: 0.4502\n",
      "\n",
      "Epoch 118/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4485 - acc: 0.5406Epoch 00118: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4486 - acc: 0.5406 - val_loss: 1.8057 - val_acc: 0.4420\n",
      "\n",
      "Epoch 119/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4487 - acc: 0.5415Epoch 00119: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4487 - acc: 0.5415 - val_loss: 1.7912 - val_acc: 0.4505\n",
      "\n",
      "Epoch 120/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4491 - acc: 0.5427Epoch 00120: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4491 - acc: 0.5427 - val_loss: 1.7935 - val_acc: 0.4506\n",
      "\n",
      "Epoch 121/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4411 - acc: 0.5441Epoch 00121: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4411 - acc: 0.5441 - val_loss: 1.7811 - val_acc: 0.4534\n",
      "\n",
      "Epoch 122/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4396 - acc: 0.5456Epoch 00122: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4397 - acc: 0.5455 - val_loss: 1.7978 - val_acc: 0.4470\n",
      "\n",
      "Epoch 123/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4494 - acc: 0.5421Epoch 00123: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4493 - acc: 0.5421 - val_loss: 1.7791 - val_acc: 0.4558\n",
      "\n",
      "Epoch 124/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4403 - acc: 0.5461Epoch 00124: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4404 - acc: 0.5461 - val_loss: 1.7872 - val_acc: 0.4534\n",
      "\n",
      "Epoch 125/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4304 - acc: 0.5476Epoch 00125: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4304 - acc: 0.5476 - val_loss: 1.7822 - val_acc: 0.4558\n",
      "\n",
      "Epoch 126/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4411 - acc: 0.5446Epoch 00126: val_acc improved from 0.45656 to 0.45836, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4409 - acc: 0.5447 - val_loss: 1.7800 - val_acc: 0.4584\n",
      "\n",
      "Epoch 127/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4392 - acc: 0.5455Epoch 00127: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4391 - acc: 0.5456 - val_loss: 1.7892 - val_acc: 0.4522\n",
      "\n",
      "Epoch 128/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4358 - acc: 0.5472Epoch 00128: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4357 - acc: 0.5473 - val_loss: 1.7861 - val_acc: 0.4542\n",
      "\n",
      "Epoch 129/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4316 - acc: 0.5471Epoch 00129: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4316 - acc: 0.5471 - val_loss: 1.7893 - val_acc: 0.4539\n",
      "\n",
      "Epoch 130/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4373 - acc: 0.5461Epoch 00130: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4371 - acc: 0.5462 - val_loss: 1.7840 - val_acc: 0.4542\n",
      "\n",
      "Epoch 131/400\n",
      " 996/1000 [============================>.] 996/1000 [============================>.] - ETA: 0s - loss: 1.4339 - acc: 0.5458Epoch 00131: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4339 - acc: 0.5458 - val_loss: 1.7780 - val_acc: 0.4530\n",
      "\n",
      "Epoch 132/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4355 - acc: 0.5463Epoch 00132: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4357 - acc: 0.5462 - val_loss: 1.7975 - val_acc: 0.4516\n",
      "\n",
      "Epoch 133/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4365 - acc: 0.5484Epoch 00133: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4364 - acc: 0.5484 - val_loss: 1.7836 - val_acc: 0.4569\n",
      "\n",
      "Epoch 134/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4337 - acc: 0.5458Epoch 00134: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4338 - acc: 0.5458 - val_loss: 1.7898 - val_acc: 0.4550\n",
      "\n",
      "Epoch 135/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4355 - acc: 0.5473Epoch 00135: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4355 - acc: 0.5473 - val_loss: 1.7867 - val_acc: 0.4548\n",
      "\n",
      "Epoch 136/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4391 - acc: 0.5444Epoch 00136: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4390 - acc: 0.5444 - val_loss: 1.7695 - val_acc: 0.4522\n",
      "\n",
      "Epoch 137/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4393 - acc: 0.5456Epoch 00137: val_acc improved from 0.45836 to 0.46000, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4393 - acc: 0.5456 - val_loss: 1.7819 - val_acc: 0.4600\n",
      "\n",
      "Epoch 138/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4234 - acc: 0.5488Epoch 00138: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4235 - acc: 0.5488 - val_loss: 1.7850 - val_acc: 0.4516\n",
      "\n",
      "Epoch 139/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4376 - acc: 0.5456Epoch 00139: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4377 - acc: 0.5456 - val_loss: 1.7755 - val_acc: 0.4574\n",
      "\n",
      "Epoch 140/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4327 - acc: 0.5475Epoch 00140: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4327 - acc: 0.5475 - val_loss: 1.7789 - val_acc: 0.4573\n",
      "\n",
      "Epoch 141/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4309 - acc: 0.5485Epoch 00141: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4308 - acc: 0.5485 - val_loss: 1.7835 - val_acc: 0.4570\n",
      "\n",
      "Epoch 142/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4282 - acc: 0.5488Epoch 00142: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4282 - acc: 0.5488 - val_loss: 1.7900 - val_acc: 0.4546\n",
      "\n",
      "Epoch 143/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4332 - acc: 0.5468Epoch 00143: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4332 - acc: 0.5468 - val_loss: 1.7817 - val_acc: 0.4545\n",
      "\n",
      "Epoch 144/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4266 - acc: 0.5498Epoch 00144: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4265 - acc: 0.5498 - val_loss: 1.7916 - val_acc: 0.4512\n",
      "\n",
      "Epoch 145/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4311 - acc: 0.5474Epoch 00145: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 105s 105ms/step - loss: 1.4310 - acc: 0.5474 - val_loss: 1.7846 - val_acc: 0.4553\n",
      "\n",
      "Epoch 146/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4339 - acc: 0.5482Epoch 00146: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 107s 107ms/step - loss: 1.4338 - acc: 0.5482 - val_loss: 1.7899 - val_acc: 0.4559\n",
      "\n",
      "Epoch 147/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4330 - acc: 0.5449Epoch 00147: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4329 - acc: 0.5449 - val_loss: 1.7899 - val_acc: 0.4561\n",
      "\n",
      "Epoch 148/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4385 - acc: 0.5461Epoch 00148: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4386 - acc: 0.5460 - val_loss: 1.7872 - val_acc: 0.4533\n",
      "\n",
      "Epoch 149/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4357 - acc: 0.5463Epoch 00149: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4357 - acc: 0.5463 - val_loss: 1.7800 - val_acc: 0.4514\n",
      "\n",
      "Epoch 150/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4378 - acc: 0.5469Epoch 00150: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4378 - acc: 0.5469 - val_loss: 1.7791 - val_acc: 0.4551\n",
      "\n",
      "Epoch 151/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4228 - acc: 0.5494Epoch 00151: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4227 - acc: 0.5494 - val_loss: 1.7781 - val_acc: 0.4533\n",
      "\n",
      "Epoch 152/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4329 - acc: 0.5478Epoch 00152: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4330 - acc: 0.5478 - val_loss: 1.7726 - val_acc: 0.4575\n",
      "\n",
      "Epoch 153/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4269 - acc: 0.5491Epoch 00153: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4269 - acc: 0.5490 - val_loss: 1.7870 - val_acc: 0.4556\n",
      "\n",
      "Epoch 154/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4311 - acc: 0.5487Epoch 00154: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4311 - acc: 0.5488 - val_loss: 1.7821 - val_acc: 0.4562\n",
      "\n",
      "Epoch 155/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4276 - acc: 0.5485Epoch 00155: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4276 - acc: 0.5486 - val_loss: 1.7895 - val_acc: 0.4507\n",
      "\n",
      "Epoch 156/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4335 - acc: 0.5471Epoch 00156: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4336 - acc: 0.5470 - val_loss: 1.7774 - val_acc: 0.4558\n",
      "\n",
      "Epoch 157/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4291 - acc: 0.5476Epoch 00157: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4290 - acc: 0.5476 - val_loss: 1.7780 - val_acc: 0.4547\n",
      "\n",
      "Epoch 158/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4279 - acc: 0.5503Epoch 00158: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4278 - acc: 0.5503 - val_loss: 1.7924 - val_acc: 0.4532\n",
      "\n",
      "Epoch 159/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4329 - acc: 0.5487Epoch 00159: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4328 - acc: 0.5487 - val_loss: 1.7752 - val_acc: 0.4562\n",
      "\n",
      "Epoch 160/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4267 - acc: 0.5474Epoch 00160: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4265 - acc: 0.5475 - val_loss: 1.7743 - val_acc: 0.4580\n",
      "\n",
      "Epoch 161/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4337 - acc: 0.5482Epoch 00161: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4337 - acc: 0.5482 - val_loss: 1.7792 - val_acc: 0.4550\n",
      "\n",
      "Epoch 162/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4286 - acc: 0.5485Epoch 00162: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 107s 107ms/step - loss: 1.4285 - acc: 0.5486 - val_loss: 1.7824 - val_acc: 0.4548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 163/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4319 - acc: 0.5485Epoch 00163: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4319 - acc: 0.5485 - val_loss: 1.7833 - val_acc: 0.4567\n",
      "\n",
      "Epoch 164/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4237 - acc: 0.5486Epoch 00164: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 107s 107ms/step - loss: 1.4236 - acc: 0.5486 - val_loss: 1.7825 - val_acc: 0.4532\n",
      "\n",
      "Epoch 165/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4300 - acc: 0.5486Epoch 00165: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4300 - acc: 0.5486 - val_loss: 1.7791 - val_acc: 0.4577\n",
      "\n",
      "Epoch 166/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4232 - acc: 0.5498Epoch 00166: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4233 - acc: 0.5497 - val_loss: 1.7839 - val_acc: 0.4570\n",
      "\n",
      "Epoch 167/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4286 - acc: 0.5491Epoch 00167: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4286 - acc: 0.5491 - val_loss: 1.7834 - val_acc: 0.4575\n",
      "\n",
      "Epoch 168/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4250 - acc: 0.5498Epoch 00168: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4250 - acc: 0.5499 - val_loss: 1.7866 - val_acc: 0.4550\n",
      "\n",
      "Epoch 169/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4270 - acc: 0.5476Epoch 00169: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4269 - acc: 0.5477 - val_loss: 1.7815 - val_acc: 0.4541\n",
      "\n",
      "Epoch 170/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4245 - acc: 0.5494Epoch 00170: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4245 - acc: 0.5495 - val_loss: 1.7826 - val_acc: 0.4547\n",
      "\n",
      "Epoch 171/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4264 - acc: 0.5508Epoch 00171: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4263 - acc: 0.5508 - val_loss: 1.7784 - val_acc: 0.4559\n",
      "\n",
      "Epoch 172/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4283 - acc: 0.5493Epoch 00172: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4283 - acc: 0.5493 - val_loss: 1.7750 - val_acc: 0.4577\n",
      "\n",
      "Epoch 173/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4255 - acc: 0.5481Epoch 00173: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4256 - acc: 0.5481 - val_loss: 1.7821 - val_acc: 0.4563\n",
      "\n",
      "Epoch 174/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4339 - acc: 0.5466Epoch 00174: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4339 - acc: 0.5465 - val_loss: 1.7776 - val_acc: 0.4558\n",
      "\n",
      "Epoch 175/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4284 - acc: 0.5492Epoch 00175: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4285 - acc: 0.5492 - val_loss: 1.7718 - val_acc: 0.4570\n",
      "\n",
      "Epoch 176/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4265 - acc: 0.5502Epoch 00176: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4265 - acc: 0.5502 - val_loss: 1.7809 - val_acc: 0.4578\n",
      "\n",
      "Epoch 177/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4207 - acc: 0.5508Epoch 00177: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4207 - acc: 0.5507 - val_loss: 1.7853 - val_acc: 0.4531\n",
      "\n",
      "Epoch 178/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4307 - acc: 0.5479Epoch 00178: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4307 - acc: 0.5479 - val_loss: 1.7856 - val_acc: 0.4578\n",
      "\n",
      "Epoch 179/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4213 - acc: 0.5523Epoch 00179: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4214 - acc: 0.5523 - val_loss: 1.7818 - val_acc: 0.4572\n",
      "\n",
      "Epoch 180/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4249 - acc: 0.5495Epoch 00180: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4249 - acc: 0.5495 - val_loss: 1.7797 - val_acc: 0.4599\n",
      "\n",
      "Epoch 181/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4219 - acc: 0.5502Epoch 00181: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4219 - acc: 0.5502 - val_loss: 1.7837 - val_acc: 0.4534\n",
      "\n",
      "Epoch 182/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4232 - acc: 0.5498Epoch 00182: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4232 - acc: 0.5498 - val_loss: 1.7766 - val_acc: 0.4580\n",
      "\n",
      "Epoch 183/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4216 - acc: 0.5501Epoch 00183: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4217 - acc: 0.5501 - val_loss: 1.7796 - val_acc: 0.4558\n",
      "\n",
      "Epoch 184/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4277 - acc: 0.5512Epoch 00184: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4278 - acc: 0.5512 - val_loss: 1.7800 - val_acc: 0.4570\n",
      "\n",
      "Epoch 185/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4258 - acc: 0.5496Epoch 00185: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4258 - acc: 0.5496 - val_loss: 1.7788 - val_acc: 0.4581\n",
      "\n",
      "Epoch 186/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4224 - acc: 0.5480Epoch 00186: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4226 - acc: 0.5479 - val_loss: 1.7822 - val_acc: 0.4589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 187/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4338 - acc: 0.5469Epoch 00187: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4339 - acc: 0.5469 - val_loss: 1.7724 - val_acc: 0.4591\n",
      "\n",
      "Epoch 188/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4259 - acc: 0.5502Epoch 00188: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4259 - acc: 0.5502 - val_loss: 1.7747 - val_acc: 0.4591\n",
      "\n",
      "Epoch 189/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4253 - acc: 0.5494Epoch 00189: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4251 - acc: 0.5494 - val_loss: 1.7831 - val_acc: 0.4575\n",
      "\n",
      "Epoch 190/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4211 - acc: 0.5511Epoch 00190: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4212 - acc: 0.5511 - val_loss: 1.7788 - val_acc: 0.4591\n",
      "\n",
      "Epoch 191/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4296 - acc: 0.5484Epoch 00191: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4296 - acc: 0.5484 - val_loss: 1.7826 - val_acc: 0.4589\n",
      "\n",
      "Epoch 192/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4198 - acc: 0.5520Epoch 00192: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4197 - acc: 0.5520 - val_loss: 1.7839 - val_acc: 0.4572\n",
      "\n",
      "Epoch 193/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4233 - acc: 0.5503Epoch 00193: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4231 - acc: 0.5503 - val_loss: 1.7791 - val_acc: 0.4587\n",
      "\n",
      "Epoch 194/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4210 - acc: 0.5502Epoch 00194: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4211 - acc: 0.5502 - val_loss: 1.7789 - val_acc: 0.4561\n",
      "\n",
      "Epoch 195/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4214 - acc: 0.5499Epoch 00195: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4215 - acc: 0.5498 - val_loss: 1.7810 - val_acc: 0.4556\n",
      "\n",
      "Epoch 196/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4213 - acc: 0.5506Epoch 00196: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4212 - acc: 0.5506 - val_loss: 1.7808 - val_acc: 0.4559\n",
      "\n",
      "Epoch 197/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4274 - acc: 0.5518Epoch 00197: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4273 - acc: 0.5518 - val_loss: 1.7821 - val_acc: 0.4564\n",
      "\n",
      "Epoch 198/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4250 - acc: 0.5500Epoch 00198: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 107s 107ms/step - loss: 1.4251 - acc: 0.5499 - val_loss: 1.7789 - val_acc: 0.4564\n",
      "\n",
      "Epoch 199/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4209 - acc: 0.5499Epoch 00199: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4209 - acc: 0.5499 - val_loss: 1.7799 - val_acc: 0.4577\n",
      "\n",
      "Epoch 200/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4338 - acc: 0.5475Epoch 00200: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4337 - acc: 0.5476 - val_loss: 1.7815 - val_acc: 0.4561\n",
      "\n",
      "Epoch 201/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4242 - acc: 0.5515Epoch 00201: val_acc improved from 0.46000 to 0.46063, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4241 - acc: 0.5515 - val_loss: 1.7700 - val_acc: 0.4606\n",
      "\n",
      "Epoch 202/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4229 - acc: 0.5494Epoch 00202: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4227 - acc: 0.5495 - val_loss: 1.7855 - val_acc: 0.4589\n",
      "\n",
      "Epoch 203/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4261 - acc: 0.5487Epoch 00203: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4261 - acc: 0.5487 - val_loss: 1.7735 - val_acc: 0.4598\n",
      "\n",
      "Epoch 204/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4277 - acc: 0.5492Epoch 00204: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4277 - acc: 0.5492 - val_loss: 1.7823 - val_acc: 0.4583\n",
      "\n",
      "Epoch 205/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4195 - acc: 0.5533Epoch 00205: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4195 - acc: 0.5534 - val_loss: 1.7826 - val_acc: 0.4548\n",
      "\n",
      "Epoch 206/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4182 - acc: 0.5515Epoch 00206: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 105s 105ms/step - loss: 1.4181 - acc: 0.5515 - val_loss: 1.7813 - val_acc: 0.4558\n",
      "\n",
      "Epoch 207/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4233 - acc: 0.5496Epoch 00207: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 106s 106ms/step - loss: 1.4233 - acc: 0.5496 - val_loss: 1.7792 - val_acc: 0.4553\n",
      "\n",
      "Epoch 208/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4157 - acc: 0.5526Epoch 00208: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 107s 107ms/step - loss: 1.4157 - acc: 0.5526 - val_loss: 1.7757 - val_acc: 0.4564\n",
      "\n",
      "Epoch 209/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4207 - acc: 0.5512Epoch 00209: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4207 - acc: 0.5512 - val_loss: 1.7779 - val_acc: 0.4578\n",
      "\n",
      "Epoch 210/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4250 - acc: 0.5526Epoch 00210: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4249 - acc: 0.5527 - val_loss: 1.7853 - val_acc: 0.4562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 211/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4244 - acc: 0.5493Epoch 00211: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4244 - acc: 0.5492 - val_loss: 1.7735 - val_acc: 0.4606\n",
      "\n",
      "Epoch 212/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4214 - acc: 0.5505Epoch 00212: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4214 - acc: 0.5506 - val_loss: 1.7750 - val_acc: 0.4587\n",
      "\n",
      "Epoch 213/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4323 - acc: 0.5474Epoch 00213: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4323 - acc: 0.5474 - val_loss: 1.7760 - val_acc: 0.4578\n",
      "\n",
      "Epoch 214/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4246 - acc: 0.5508Epoch 00214: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4243 - acc: 0.5509 - val_loss: 1.7749 - val_acc: 0.4589\n",
      "\n",
      "Epoch 215/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4197 - acc: 0.5506Epoch 00215: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4196 - acc: 0.5506 - val_loss: 1.7863 - val_acc: 0.4580\n",
      "\n",
      "Epoch 216/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4257 - acc: 0.5495Epoch 00216: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4257 - acc: 0.5494 - val_loss: 1.7774 - val_acc: 0.4600\n",
      "\n",
      "Epoch 217/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4246 - acc: 0.5497Epoch 00217: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4246 - acc: 0.5498 - val_loss: 1.7774 - val_acc: 0.4572\n",
      "\n",
      "Epoch 218/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4218 - acc: 0.5517Epoch 00218: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4218 - acc: 0.5516 - val_loss: 1.7774 - val_acc: 0.4578\n",
      "\n",
      "Epoch 219/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4131 - acc: 0.5529Epoch 00219: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4128 - acc: 0.5530 - val_loss: 1.7822 - val_acc: 0.4586\n",
      "\n",
      "Epoch 220/400\n",
      " 996/1000 [============================>.] 996/1000 [============================>.] - ETA: 0s - loss: 1.4252 - acc: 0.5499Epoch 00220: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4249 - acc: 0.5501 - val_loss: 1.7757 - val_acc: 0.4581\n",
      "\n",
      "Epoch 221/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4148 - acc: 0.5528Epoch 00221: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4150 - acc: 0.5527 - val_loss: 1.7779 - val_acc: 0.4566\n",
      "\n",
      "Epoch 222/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4212 - acc: 0.5512Epoch 00222: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 108s 108ms/step - loss: 1.4211 - acc: 0.5512 - val_loss: 1.7800 - val_acc: 0.4587\n",
      "\n",
      "Epoch 223/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4263 - acc: 0.5515Epoch 00223: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4262 - acc: 0.5515 - val_loss: 1.7798 - val_acc: 0.4573\n",
      "\n",
      "Epoch 224/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4225 - acc: 0.5499Epoch 00224: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4224 - acc: 0.5500 - val_loss: 1.7755 - val_acc: 0.4587\n",
      "\n",
      "Epoch 225/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4227 - acc: 0.5501Epoch 00225: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 110s 110ms/step - loss: 1.4227 - acc: 0.5502 - val_loss: 1.7782 - val_acc: 0.4568\n",
      "\n",
      "Epoch 226/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4299 - acc: 0.5496Epoch 00226: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 109s 109ms/step - loss: 1.4300 - acc: 0.5495 - val_loss: 1.7792 - val_acc: 0.4572\n",
      "\n",
      "Epoch 227/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4225 - acc: 0.5510Epoch 00227: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4225 - acc: 0.5510 - val_loss: 1.7751 - val_acc: 0.4583\n",
      "\n",
      "Epoch 228/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4180 - acc: 0.5511Epoch 00228: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4180 - acc: 0.5511 - val_loss: 1.7768 - val_acc: 0.4589\n",
      "\n",
      "Epoch 229/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4268 - acc: 0.5499Epoch 00229: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4269 - acc: 0.5498 - val_loss: 1.7786 - val_acc: 0.4602\n",
      "\n",
      "Epoch 230/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4243 - acc: 0.5503Epoch 00230: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4243 - acc: 0.5503 - val_loss: 1.7766 - val_acc: 0.4584\n",
      "\n",
      "Epoch 231/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4214 - acc: 0.5513Epoch 00231: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4215 - acc: 0.5513 - val_loss: 1.7771 - val_acc: 0.4578\n",
      "\n",
      "Epoch 232/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4116 - acc: 0.5534Epoch 00232: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4115 - acc: 0.5534 - val_loss: 1.7842 - val_acc: 0.4573\n",
      "\n",
      "Epoch 233/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4223 - acc: 0.5510Epoch 00233: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4223 - acc: 0.5509 - val_loss: 1.7816 - val_acc: 0.4564\n",
      "\n",
      "Epoch 234/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4167 - acc: 0.5518Epoch 00234: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4167 - acc: 0.5518 - val_loss: 1.7770 - val_acc: 0.4579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 235/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4211 - acc: 0.5504Epoch 00235: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4212 - acc: 0.5504 - val_loss: 1.7784 - val_acc: 0.4605\n",
      "\n",
      "Epoch 236/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4257 - acc: 0.5521Epoch 00236: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4257 - acc: 0.5521 - val_loss: 1.7829 - val_acc: 0.4570\n",
      "\n",
      "Epoch 237/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4228 - acc: 0.5502Epoch 00237: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4228 - acc: 0.5502 - val_loss: 1.7732 - val_acc: 0.4603\n",
      "\n",
      "Epoch 238/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4215 - acc: 0.5520Epoch 00238: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4215 - acc: 0.5521 - val_loss: 1.7824 - val_acc: 0.4584\n",
      "\n",
      "Epoch 239/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4292 - acc: 0.5477Epoch 00239: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4292 - acc: 0.5477 - val_loss: 1.7792 - val_acc: 0.4576\n",
      "\n",
      "Epoch 240/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4260 - acc: 0.5511Epoch 00240: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4259 - acc: 0.5511 - val_loss: 1.7761 - val_acc: 0.4595\n",
      "\n",
      "Epoch 241/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4136 - acc: 0.5518Epoch 00241: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4136 - acc: 0.5518 - val_loss: 1.7768 - val_acc: 0.4589\n",
      "\n",
      "Epoch 242/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4259 - acc: 0.5495Epoch 00242: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4259 - acc: 0.5495 - val_loss: 1.7740 - val_acc: 0.4597\n",
      "\n",
      "Epoch 243/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4231 - acc: 0.5511Epoch 00243: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4232 - acc: 0.5511 - val_loss: 1.7755 - val_acc: 0.4589\n",
      "\n",
      "Epoch 244/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4216 - acc: 0.5509Epoch 00244: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4214 - acc: 0.5510 - val_loss: 1.7777 - val_acc: 0.4570\n",
      "\n",
      "Epoch 245/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4167 - acc: 0.5524Epoch 00245: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4167 - acc: 0.5524 - val_loss: 1.7815 - val_acc: 0.4559\n",
      "\n",
      "Epoch 246/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4200 - acc: 0.5515Epoch 00246: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4200 - acc: 0.5515 - val_loss: 1.7818 - val_acc: 0.4597\n",
      "\n",
      "Epoch 247/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4170 - acc: 0.5518Epoch 00247: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4169 - acc: 0.5519 - val_loss: 1.7754 - val_acc: 0.4572\n",
      "\n",
      "Epoch 248/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4221 - acc: 0.5511Epoch 00248: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4220 - acc: 0.5512 - val_loss: 1.7851 - val_acc: 0.4558\n",
      "\n",
      "Epoch 249/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4223 - acc: 0.5531Epoch 00249: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4223 - acc: 0.5531 - val_loss: 1.7792 - val_acc: 0.4575\n",
      "\n",
      "Epoch 250/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4220 - acc: 0.5478Epoch 00250: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4219 - acc: 0.5478 - val_loss: 1.7784 - val_acc: 0.4591\n",
      "\n",
      "Epoch 251/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4241 - acc: 0.5515Epoch 00251: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4240 - acc: 0.5515 - val_loss: 1.7829 - val_acc: 0.4584\n",
      "\n",
      "Epoch 252/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4280 - acc: 0.5493Epoch 00252: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4280 - acc: 0.5493 - val_loss: 1.7743 - val_acc: 0.4600\n",
      "\n",
      "Epoch 253/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4282 - acc: 0.5495Epoch 00253: val_acc improved from 0.46063 to 0.46090, saving model to checkpoint/model_weights_fourth.json\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4282 - acc: 0.5495 - val_loss: 1.7783 - val_acc: 0.4609\n",
      "\n",
      "Epoch 254/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4125 - acc: 0.5527Epoch 00254: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4126 - acc: 0.5527 - val_loss: 1.7782 - val_acc: 0.4599\n",
      "\n",
      "Epoch 255/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4273 - acc: 0.5496Epoch 00255: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4272 - acc: 0.5496 - val_loss: 1.7753 - val_acc: 0.4608\n",
      "\n",
      "Epoch 256/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4206 - acc: 0.5520Epoch 00256: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 120s 120ms/step - loss: 1.4206 - acc: 0.5520 - val_loss: 1.7761 - val_acc: 0.4605\n",
      "\n",
      "Epoch 257/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4226 - acc: 0.5503Epoch 00257: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4226 - acc: 0.5503 - val_loss: 1.7790 - val_acc: 0.4577\n",
      "\n",
      "Epoch 258/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4164 - acc: 0.5529Epoch 00258: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4164 - acc: 0.5529 - val_loss: 1.7797 - val_acc: 0.4577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 259/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4204 - acc: 0.5503Epoch 00259: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4204 - acc: 0.5503 - val_loss: 1.7816 - val_acc: 0.4568\n",
      "\n",
      "Epoch 260/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4159 - acc: 0.5531Epoch 00260: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4160 - acc: 0.5531 - val_loss: 1.7777 - val_acc: 0.4570\n",
      "\n",
      "Epoch 261/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4189 - acc: 0.5523Epoch 00261: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4189 - acc: 0.5523 - val_loss: 1.7783 - val_acc: 0.4592\n",
      "\n",
      "Epoch 262/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4254 - acc: 0.5509Epoch 00262: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4254 - acc: 0.5509 - val_loss: 1.7786 - val_acc: 0.4586\n",
      "\n",
      "Epoch 263/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4205 - acc: 0.5492Epoch 00263: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4204 - acc: 0.5493 - val_loss: 1.7799 - val_acc: 0.4587\n",
      "\n",
      "Epoch 264/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4274 - acc: 0.5498Epoch 00264: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4275 - acc: 0.5498 - val_loss: 1.7770 - val_acc: 0.4580\n",
      "\n",
      "Epoch 265/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4238 - acc: 0.5507Epoch 00265: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 118s 118ms/step - loss: 1.4238 - acc: 0.5506 - val_loss: 1.7760 - val_acc: 0.4577\n",
      "\n",
      "Epoch 266/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4260 - acc: 0.5505Epoch 00266: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4260 - acc: 0.5505 - val_loss: 1.7758 - val_acc: 0.4584\n",
      "\n",
      "Epoch 267/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4152 - acc: 0.5504Epoch 00267: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 118s 118ms/step - loss: 1.4154 - acc: 0.5502 - val_loss: 1.7764 - val_acc: 0.4587\n",
      "\n",
      "Epoch 268/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4240 - acc: 0.5507Epoch 00268: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4239 - acc: 0.5507 - val_loss: 1.7779 - val_acc: 0.4587\n",
      "\n",
      "Epoch 269/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4168 - acc: 0.5516Epoch 00269: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4169 - acc: 0.5516 - val_loss: 1.7769 - val_acc: 0.4591\n",
      "\n",
      "Epoch 270/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4217 - acc: 0.5511Epoch 00270: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4218 - acc: 0.5511 - val_loss: 1.7766 - val_acc: 0.4580\n",
      "\n",
      "Epoch 271/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4168 - acc: 0.5515Epoch 00271: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 118s 118ms/step - loss: 1.4170 - acc: 0.5515 - val_loss: 1.7795 - val_acc: 0.4575\n",
      "\n",
      "Epoch 272/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4222 - acc: 0.5506Epoch 00272: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4223 - acc: 0.5506 - val_loss: 1.7783 - val_acc: 0.4573\n",
      "\n",
      "Epoch 273/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4167 - acc: 0.5517Epoch 00273: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4167 - acc: 0.5517 - val_loss: 1.7781 - val_acc: 0.4573\n",
      "\n",
      "Epoch 274/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4194 - acc: 0.5524Epoch 00274: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4195 - acc: 0.5524 - val_loss: 1.7797 - val_acc: 0.4583\n",
      "\n",
      "Epoch 275/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4240 - acc: 0.5520Epoch 00275: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4239 - acc: 0.5520 - val_loss: 1.7765 - val_acc: 0.4583\n",
      "\n",
      "Epoch 276/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4200 - acc: 0.5496Epoch 00276: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4200 - acc: 0.5495 - val_loss: 1.7804 - val_acc: 0.4582\n",
      "\n",
      "Epoch 277/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4286 - acc: 0.5494Epoch 00277: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 118s 118ms/step - loss: 1.4286 - acc: 0.5494 - val_loss: 1.7758 - val_acc: 0.4597\n",
      "\n",
      "Epoch 278/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4217 - acc: 0.5512Epoch 00278: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4216 - acc: 0.5512 - val_loss: 1.7761 - val_acc: 0.4591\n",
      "\n",
      "Epoch 279/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4256 - acc: 0.5517Epoch 00279: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 118s 118ms/step - loss: 1.4257 - acc: 0.5517 - val_loss: 1.7782 - val_acc: 0.4603\n",
      "\n",
      "Epoch 280/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4176 - acc: 0.5509Epoch 00280: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4176 - acc: 0.5509 - val_loss: 1.7787 - val_acc: 0.4573\n",
      "\n",
      "Epoch 281/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4245 - acc: 0.5501Epoch 00281: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4244 - acc: 0.5502 - val_loss: 1.7767 - val_acc: 0.4580\n",
      "\n",
      "Epoch 282/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4168 - acc: 0.5526Epoch 00282: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4172 - acc: 0.5525 - val_loss: 1.7765 - val_acc: 0.4587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 283/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4203 - acc: 0.5510Epoch 00283: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4203 - acc: 0.5510 - val_loss: 1.7784 - val_acc: 0.4586\n",
      "\n",
      "Epoch 284/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4188 - acc: 0.5525Epoch 00284: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4188 - acc: 0.5525 - val_loss: 1.7798 - val_acc: 0.4581\n",
      "\n",
      "Epoch 285/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4188 - acc: 0.5500Epoch 00285: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4188 - acc: 0.5500 - val_loss: 1.7775 - val_acc: 0.4567\n",
      "\n",
      "Epoch 286/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4183 - acc: 0.5526Epoch 00286: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4184 - acc: 0.5526 - val_loss: 1.7789 - val_acc: 0.4561\n",
      "\n",
      "Epoch 287/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4205 - acc: 0.5534Epoch 00287: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4205 - acc: 0.5534 - val_loss: 1.7765 - val_acc: 0.4570\n",
      "\n",
      "Epoch 288/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4231 - acc: 0.5511Epoch 00288: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4232 - acc: 0.5511 - val_loss: 1.7768 - val_acc: 0.4606\n",
      "\n",
      "Epoch 289/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4209 - acc: 0.5502Epoch 00289: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4210 - acc: 0.5502 - val_loss: 1.7795 - val_acc: 0.4574\n",
      "\n",
      "Epoch 290/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4278 - acc: 0.5484Epoch 00290: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4278 - acc: 0.5484 - val_loss: 1.7744 - val_acc: 0.4589\n",
      "\n",
      "Epoch 291/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4241 - acc: 0.5517Epoch 00291: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4240 - acc: 0.5518 - val_loss: 1.7746 - val_acc: 0.4584\n",
      "\n",
      "Epoch 292/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4211 - acc: 0.5511Epoch 00292: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4212 - acc: 0.5511 - val_loss: 1.7773 - val_acc: 0.4598\n",
      "\n",
      "Epoch 293/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4170 - acc: 0.5513Epoch 00293: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4168 - acc: 0.5513 - val_loss: 1.7795 - val_acc: 0.4584\n",
      "\n",
      "Epoch 294/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4270 - acc: 0.5494Epoch 00294: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4270 - acc: 0.5494 - val_loss: 1.7766 - val_acc: 0.4589\n",
      "\n",
      "Epoch 295/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4155 - acc: 0.5543Epoch 00295: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4155 - acc: 0.5543 - val_loss: 1.7784 - val_acc: 0.4583\n",
      "\n",
      "Epoch 296/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4200 - acc: 0.5512Epoch 00296: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4199 - acc: 0.5512 - val_loss: 1.7766 - val_acc: 0.4598\n",
      "\n",
      "Epoch 297/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4199 - acc: 0.5511Epoch 00297: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4198 - acc: 0.5511 - val_loss: 1.7800 - val_acc: 0.4580\n",
      "\n",
      "Epoch 298/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4161 - acc: 0.5514Epoch 00298: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4161 - acc: 0.5514 - val_loss: 1.7769 - val_acc: 0.4589\n",
      "\n",
      "Epoch 299/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4167 - acc: 0.5526Epoch 00299: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4169 - acc: 0.5526 - val_loss: 1.7786 - val_acc: 0.4583\n",
      "\n",
      "Epoch 300/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4243 - acc: 0.5530Epoch 00300: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4243 - acc: 0.5530 - val_loss: 1.7764 - val_acc: 0.4584\n",
      "\n",
      "Epoch 301/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4227 - acc: 0.5507Epoch 00301: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4227 - acc: 0.5507 - val_loss: 1.7772 - val_acc: 0.4592\n",
      "\n",
      "Epoch 302/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4190 - acc: 0.5502Epoch 00302: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4189 - acc: 0.5502 - val_loss: 1.7783 - val_acc: 0.4572\n",
      "\n",
      "Epoch 303/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4295 - acc: 0.5489Epoch 00303: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4296 - acc: 0.5489 - val_loss: 1.7759 - val_acc: 0.4589\n",
      "\n",
      "Epoch 304/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4225 - acc: 0.5525Epoch 00304: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4225 - acc: 0.5525 - val_loss: 1.7749 - val_acc: 0.4573\n",
      "\n",
      "Epoch 305/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4212 - acc: 0.5508Epoch 00305: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4211 - acc: 0.5508 - val_loss: 1.7776 - val_acc: 0.4598\n",
      "\n",
      "Epoch 306/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4203 - acc: 0.5507Epoch 00306: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4202 - acc: 0.5508 - val_loss: 1.7778 - val_acc: 0.4582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 307/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4261 - acc: 0.5495Epoch 00307: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4261 - acc: 0.5495 - val_loss: 1.7775 - val_acc: 0.4580\n",
      "\n",
      "Epoch 308/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4159 - acc: 0.5537Epoch 00308: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4160 - acc: 0.5537 - val_loss: 1.7778 - val_acc: 0.4588\n",
      "\n",
      "Epoch 309/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4185 - acc: 0.5514Epoch 00309: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4186 - acc: 0.5513 - val_loss: 1.7776 - val_acc: 0.4595\n",
      "\n",
      "Epoch 310/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4186 - acc: 0.5524Epoch 00310: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4187 - acc: 0.5524 - val_loss: 1.7797 - val_acc: 0.4574\n",
      "\n",
      "Epoch 311/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4186 - acc: 0.5502Epoch 00311: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4186 - acc: 0.5502 - val_loss: 1.7780 - val_acc: 0.4584\n",
      "\n",
      "Epoch 312/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4171 - acc: 0.5516Epoch 00312: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4171 - acc: 0.5516 - val_loss: 1.7775 - val_acc: 0.4572\n",
      "\n",
      "Epoch 313/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4222 - acc: 0.5525Epoch 00313: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 117s 117ms/step - loss: 1.4222 - acc: 0.5525 - val_loss: 1.7770 - val_acc: 0.4586\n",
      "\n",
      "Epoch 314/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4217 - acc: 0.5513Epoch 00314: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4216 - acc: 0.5512 - val_loss: 1.7773 - val_acc: 0.4592\n",
      "\n",
      "Epoch 315/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4195 - acc: 0.5501Epoch 00315: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4195 - acc: 0.5501 - val_loss: 1.7786 - val_acc: 0.4577\n",
      "\n",
      "Epoch 316/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4299 - acc: 0.5483Epoch 00316: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4299 - acc: 0.5484 - val_loss: 1.7779 - val_acc: 0.4587\n",
      "\n",
      "Epoch 317/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4209 - acc: 0.5532Epoch 00317: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4210 - acc: 0.5532 - val_loss: 1.7744 - val_acc: 0.4594\n",
      "\n",
      "Epoch 318/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4183 - acc: 0.5506Epoch 00318: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4184 - acc: 0.5505 - val_loss: 1.7788 - val_acc: 0.4597\n",
      "\n",
      "Epoch 319/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4245 - acc: 0.5495Epoch 00319: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4246 - acc: 0.5495 - val_loss: 1.7762 - val_acc: 0.4592\n",
      "\n",
      "Epoch 320/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4243 - acc: 0.5501Epoch 00320: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4240 - acc: 0.5502 - val_loss: 1.7787 - val_acc: 0.4575\n",
      "\n",
      "Epoch 321/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4174 - acc: 0.5543Epoch 00321: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4174 - acc: 0.5543 - val_loss: 1.7765 - val_acc: 0.4598\n",
      "\n",
      "Epoch 322/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4142 - acc: 0.5525Epoch 00322: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4143 - acc: 0.5525 - val_loss: 1.7773 - val_acc: 0.4589\n",
      "\n",
      "Epoch 323/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4223 - acc: 0.5493Epoch 00323: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4223 - acc: 0.5493 - val_loss: 1.7796 - val_acc: 0.4574\n",
      "\n",
      "Epoch 324/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4131 - acc: 0.5538Epoch 00324: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4129 - acc: 0.5538 - val_loss: 1.7770 - val_acc: 0.4594\n",
      "\n",
      "Epoch 325/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4187 - acc: 0.5511Epoch 00325: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4187 - acc: 0.5511 - val_loss: 1.7774 - val_acc: 0.4581\n",
      "\n",
      "Epoch 326/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4232 - acc: 0.5532Epoch 00326: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4230 - acc: 0.5532 - val_loss: 1.7777 - val_acc: 0.4594\n",
      "\n",
      "Epoch 327/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4227 - acc: 0.5500Epoch 00327: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4227 - acc: 0.5500 - val_loss: 1.7768 - val_acc: 0.4599\n",
      "\n",
      "Epoch 328/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4182 - acc: 0.5511Epoch 00328: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4182 - acc: 0.5511 - val_loss: 1.7781 - val_acc: 0.4569\n",
      "\n",
      "Epoch 329/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4296 - acc: 0.5486Epoch 00329: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4296 - acc: 0.5486 - val_loss: 1.7774 - val_acc: 0.4586\n",
      "\n",
      "Epoch 330/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4226 - acc: 0.5523Epoch 00330: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4226 - acc: 0.5523 - val_loss: 1.7765 - val_acc: 0.4578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 331/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4162 - acc: 0.5512Epoch 00331: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4160 - acc: 0.5512 - val_loss: 1.7786 - val_acc: 0.4594\n",
      "\n",
      "Epoch 332/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4246 - acc: 0.5496Epoch 00332: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4244 - acc: 0.5496 - val_loss: 1.7768 - val_acc: 0.4597\n",
      "\n",
      "Epoch 333/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4233 - acc: 0.5503Epoch 00333: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 119s 119ms/step - loss: 1.4233 - acc: 0.5503 - val_loss: 1.7779 - val_acc: 0.4583\n",
      "\n",
      "Epoch 334/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4206 - acc: 0.5522Epoch 00334: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4206 - acc: 0.5522 - val_loss: 1.7759 - val_acc: 0.4592\n",
      "\n",
      "Epoch 335/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4105 - acc: 0.5539Epoch 00335: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4105 - acc: 0.5539 - val_loss: 1.7776 - val_acc: 0.4587\n",
      "\n",
      "Epoch 336/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4226 - acc: 0.5505Epoch 00336: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4226 - acc: 0.5504 - val_loss: 1.7782 - val_acc: 0.4586\n",
      "\n",
      "Epoch 337/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4147 - acc: 0.5525Epoch 00337: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 118s 118ms/step - loss: 1.4146 - acc: 0.5525 - val_loss: 1.7766 - val_acc: 0.4594\n",
      "\n",
      "Epoch 338/400\n",
      " 997/1000 [============================>.] 997/1000 [============================>.] - ETA: 0s - loss: 1.4192 - acc: 0.5512Epoch 00338: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 116s 116ms/step - loss: 1.4193 - acc: 0.5512 - val_loss: 1.7772 - val_acc: 0.4595\n",
      "\n",
      "Epoch 339/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4234 - acc: 0.5530Epoch 00339: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4234 - acc: 0.5530 - val_loss: 1.7777 - val_acc: 0.4583\n",
      "\n",
      "Epoch 340/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4196 - acc: 0.5512Epoch 00340: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4195 - acc: 0.5512 - val_loss: 1.7767 - val_acc: 0.4591\n",
      "\n",
      "Epoch 341/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4214 - acc: 0.5512Epoch 00341: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4215 - acc: 0.5512 - val_loss: 1.7778 - val_acc: 0.4577\n",
      "\n",
      "Epoch 342/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4289 - acc: 0.5483Epoch 00342: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4288 - acc: 0.5483 - val_loss: 1.7777 - val_acc: 0.4584\n",
      "\n",
      "Epoch 343/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4212 - acc: 0.5520Epoch 00343: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4214 - acc: 0.5520 - val_loss: 1.7759 - val_acc: 0.4583\n",
      "\n",
      "Epoch 344/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4175 - acc: 0.5517Epoch 00344: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4174 - acc: 0.5517 - val_loss: 1.7774 - val_acc: 0.4598\n",
      "\n",
      "Epoch 345/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4256 - acc: 0.5503Epoch 00345: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4257 - acc: 0.5503 - val_loss: 1.7778 - val_acc: 0.4601\n",
      "\n",
      "Epoch 346/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4232 - acc: 0.5514Epoch 00346: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4232 - acc: 0.5514 - val_loss: 1.7776 - val_acc: 0.4578\n",
      "\n",
      "Epoch 347/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4199 - acc: 0.5521Epoch 00347: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4198 - acc: 0.5522 - val_loss: 1.7771 - val_acc: 0.4595\n",
      "\n",
      "Epoch 348/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4124 - acc: 0.5531Epoch 00348: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4125 - acc: 0.5531 - val_loss: 1.7788 - val_acc: 0.4585\n",
      "\n",
      "Epoch 349/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4196 - acc: 0.5511Epoch 00349: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4196 - acc: 0.5511 - val_loss: 1.7785 - val_acc: 0.4584\n",
      "\n",
      "Epoch 350/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4170 - acc: 0.5518Epoch 00350: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 114s 114ms/step - loss: 1.4171 - acc: 0.5518 - val_loss: 1.7779 - val_acc: 0.4592\n",
      "\n",
      "Epoch 351/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4186 - acc: 0.5512Epoch 00351: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4186 - acc: 0.5512 - val_loss: 1.7772 - val_acc: 0.4595\n",
      "\n",
      "Epoch 352/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4247 - acc: 0.5518Epoch 00352: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4246 - acc: 0.5518 - val_loss: 1.7777 - val_acc: 0.4586\n",
      "\n",
      "Epoch 353/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4213 - acc: 0.5502Epoch 00353: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 115s 115ms/step - loss: 1.4213 - acc: 0.5501 - val_loss: 1.7766 - val_acc: 0.4595\n",
      "\n",
      "Epoch 354/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4193 - acc: 0.5517Epoch 00354: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4193 - acc: 0.5517 - val_loss: 1.7791 - val_acc: 0.4577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 355/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4288 - acc: 0.5491Epoch 00355: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4287 - acc: 0.5491 - val_loss: 1.7785 - val_acc: 0.4593\n",
      "\n",
      "Epoch 356/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4253 - acc: 0.5510Epoch 00356: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4252 - acc: 0.5510 - val_loss: 1.7770 - val_acc: 0.4579\n",
      "\n",
      "Epoch 357/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4122 - acc: 0.5533Epoch 00357: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4121 - acc: 0.5533 - val_loss: 1.7776 - val_acc: 0.4592\n",
      "\n",
      "Epoch 358/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4259 - acc: 0.5492Epoch 00358: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4259 - acc: 0.5492 - val_loss: 1.7773 - val_acc: 0.4591\n",
      "\n",
      "Epoch 359/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4219 - acc: 0.5514Epoch 00359: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4221 - acc: 0.5513 - val_loss: 1.7769 - val_acc: 0.4587\n",
      "\n",
      "Epoch 360/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4192 - acc: 0.5515Epoch 00360: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4190 - acc: 0.5515 - val_loss: 1.7767 - val_acc: 0.4580\n",
      "\n",
      "Epoch 361/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4155 - acc: 0.5525Epoch 00361: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 113s 113ms/step - loss: 1.4156 - acc: 0.5525 - val_loss: 1.7777 - val_acc: 0.4580\n",
      "\n",
      "Epoch 362/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4185 - acc: 0.5511Epoch 00362: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4184 - acc: 0.5511 - val_loss: 1.7787 - val_acc: 0.4587\n",
      "\n",
      "Epoch 363/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4157 - acc: 0.5523Epoch 00363: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4157 - acc: 0.5523 - val_loss: 1.7773 - val_acc: 0.4584\n",
      "\n",
      "Epoch 364/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4204 - acc: 0.5517Epoch 00364: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4205 - acc: 0.5517 - val_loss: 1.7779 - val_acc: 0.4584\n",
      "\n",
      "Epoch 365/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4228 - acc: 0.5525Epoch 00365: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 111s 111ms/step - loss: 1.4228 - acc: 0.5525 - val_loss: 1.7781 - val_acc: 0.4589\n",
      "\n",
      "Epoch 366/400\n",
      " 999/1000 [============================>.] 999/1000 [============================>.] - ETA: 0s - loss: 1.4208 - acc: 0.5497Epoch 00366: val_acc did not improve\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 112s 112ms/step - loss: 1.4209 - acc: 0.5497 - val_loss: 1.7776 - val_acc: 0.4600\n",
      "\n",
      "Epoch 367/400\n",
      " 998/1000 [============================>.] 998/1000 [============================>.] - ETA: 0s - loss: 1.4227 - acc: 0.5512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-6790:\n",
      "Process ForkPoolWorker-6792:\n",
      "Process ForkPoolWorker-6735:\n",
      "Process ForkPoolWorker-6791:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-6793:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-6734:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 247, in __getitem__\n",
      "    model_environment_input = np.array([df.iloc[:, 1:].values for df in model_input_data])\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 247, in <listcomp>\n",
      "    model_environment_input = np.array([df.iloc[:, 1:].values for df in model_input_data])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1325, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1678, in _getitem_tuple\n",
      "    retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 209, in random_subset\n",
      "    ts = df[idx:idx+window_size]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 209, in random_subset\n",
      "    ts = df[idx:idx+window_size]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\", line 1954, in __getitem__\n",
      "    return self._getitem_slice(indexer)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\", line 1954, in __getitem__\n",
      "    return self._getitem_slice(indexer)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\", line 1981, in _getitem_slice\n",
      "    return self._slice(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\", line 1981, in _getitem_slice\n",
      "    return self._slice(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1724, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 1748, in _slice\n",
      "    axis = self._get_block_manager_axis(axis)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 1749, in _slice\n",
      "    result = self._constructor(self._data.get_slice(slobj, axis=axis))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 2061, in xs\n",
      "    result.index = new_index\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 2060, in xs\n",
      "    result = self.iloc[loc]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 3094, in __setattr__\n",
      "    return object.__setattr__(self, name, value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 372, in _get_block_manager_axis\n",
      "    def _get_block_manager_axis(self, axis):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 3400, in get_slice\n",
      "    fastpath=True)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1695, in _get_slice_axis\n",
      "    slice_obj = self._convert_slice_indexer(slice_obj, axis)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 1749, in _slice\n",
      "    result = self._constructor(self._data.get_slice(slobj, axis=axis))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 473, in _set_axis\n",
      "    self._data.set_axis(axis, labels)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1724, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 241, in _convert_slice_indexer\n",
      "    return ax._convert_slice_indexer(key, kind=self.name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1697, in _get_slice_axis\n",
      "    return self._slice(slice_obj, axis=axis, kind='iloc')\n",
      "  File \"pandas/_libs/src/properties.pyx\", line 65, in pandas._libs.lib.AxisProperty.__set__ (pandas/_libs/lib.c:45255)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\", line 1362, in _convert_slice_indexer\n",
      "    self._validate_indexer('slice', key.stop, kind),\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 142, in _slice\n",
      "    return self.obj._slice(obj, axis=axis, kind=kind)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 2799, in __init__\n",
      "    self._rebuild_blknos_and_blklocs()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 2830, in set_axis\n",
      "    old_len = len(self.axes[axis])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 2890, in _rebuild_blknos_and_blklocs\n",
      "    if (new_blknos == -1).any():\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 3397, in get_slice\n",
      "    new_axes[axis] = new_axes[axis][slobj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 499, in __len__\n",
      "    return len(self.labels[0])\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-6736:\n",
      "Process ForkPoolWorker-6737:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1325, in __getitem__\n",
      "    return self._getitem_tuple(key)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 247, in __getitem__\n",
      "    model_environment_input = np.array([df.iloc[:, 1:].values for df in model_input_data])\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 247, in <listcomp>\n",
      "    model_environment_input = np.array([df.iloc[:, 1:].values for df in model_input_data])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1678, in _getitem_tuple\n",
      "    retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1724, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1697, in _get_slice_axis\n",
      "    return self._slice(slice_obj, axis=axis, kind='iloc')\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 142, in _slice\n",
      "    return self.obj._slice(obj, axis=axis, kind=kind)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 1749, in _slice\n",
      "    result = self._constructor(self._data.get_slice(slobj, axis=axis))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 3389, in get_slice\n",
      "    new_blocks = self._slice_take_blocks_ax0(slobj)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 2030, in xs\n",
      "    drop_level=drop_level)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 3918, in _slice_take_blocks_ax0\n",
      "    slice_or_indexer, self.shape[0], allow_fill=allow_fill)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 5259, in _preprocess_slice_or_indexer\n",
      "    return 'slice', slice_or_indexer, lib.slice_len(slice_or_indexer,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 2164, in get_loc_level\n",
      "    return indexer, maybe_droplevels(indexer, [level], drop_level)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 2050, in maybe_droplevels\n",
      "    orig_index = new_index = self[indexer]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 1399, in __getitem__\n",
      "    verify_integrity=False)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 108, in __new__\n",
      "    result._set_names(names)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 531, in _set_names\n",
      "    self.levels[l].rename(name, inplace=True)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\", line 1140, in rename\n",
      "    return self.set_names([name], inplace=inplace)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\", line 1112, in set_names\n",
      "    if not is_list_like(names):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/dtypes/inference.py\", line 265, in is_list_like\n",
      "    return (hasattr(obj, '__iter__') and\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-6805:\n",
      "Process ForkPoolWorker-6801:\n",
      "Process ForkPoolWorker-6803:\n",
      "Process ForkPoolWorker-6797:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-6796:\n",
      "Process ForkPoolWorker-6799:\n",
      "Process ForkPoolWorker-6807:\n",
      "Process ForkPoolWorker-6794:\n",
      "Process ForkPoolWorker-6795:\n",
      "Process ForkPoolWorker-6804:\n",
      "Process ForkPoolWorker-6798:\n",
      "Process ForkPoolWorker-6800:\n",
      "Process ForkPoolWorker-6806:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-6802:\n",
      "Process ForkPoolWorker-6809:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 208, in random_subset\n",
      "    idx = np.random.randint(0, df.shape[0]-window_size)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\", line 402, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in __getitem__\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "  File \"<ipython-input-2-fb4e503b1af8>\", line 244, in <listcomp>\n",
      "    model_input_data = [random_subset(self.stocks_data.loc[t], self.window_size) for t in df.ticker]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 2060, in xs\n",
      "    result = self.iloc[loc]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1552, in _getitem_axis\n",
      "    return self._get_label(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1724, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 136, in _get_label\n",
      "    return self.obj._xs(label, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1697, in _get_slice_axis\n",
      "    return self._slice(slice_obj, axis=axis, kind='iloc')\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 2027, in xs\n",
      "    index = self.index\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 2060, in xs\n",
      "    result = self.iloc[loc]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 2060, in xs\n",
      "    result = self.iloc[loc]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 142, in _slice\n",
      "    return self.obj._slice(obj, axis=axis, kind=kind)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 1749, in _slice\n",
      "    result = self._constructor(self._data.get_slice(slobj, axis=axis))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n",
      "    return self._getitem_axis(key, axis=0)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 3394, in get_slice\n",
      "    new_blocks = [blk.getitem_block(slicer) for blk in self.blocks]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1724, in _getitem_axis\n",
      "    return self._get_slice_axis(key, axis=axis)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 3394, in <listcomp>\n",
      "    new_blocks = [blk.getitem_block(slicer) for blk in self.blocks]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 1697, in _get_slice_axis\n",
      "    return self._slice(slice_obj, axis=axis, kind='iloc')\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 293, in getitem_block\n",
      "    return self.make_block_same_class(new_values, new_mgr_locs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 220, in make_block_same_class\n",
      "    fastpath=fastpath, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\", line 142, in _slice\n",
      "    return self.obj._slice(obj, axis=axis, kind=kind)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 2719, in make_block\n",
      "    return klass(values, ndim=ndim, fastpath=fastpath, placement=placement)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\", line 1749, in _slice\n",
      "    result = self._constructor(self._data.get_slice(slobj, axis=axis))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 109, in __init__\n",
      "    self.mgr_locs = placement\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\", line 3397, in get_slice\n",
      "    new_axes[axis] = new_axes[axis][slobj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 1399, in __getitem__\n",
      "    verify_integrity=False)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 108, in __new__\n",
      "    result._set_names(names)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/multi.py\", line 516, in _set_names\n",
      "    names = list(names)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   2321\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m         \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   2193\u001b[0m                   \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                   use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   2195\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   2353\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0menqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2354\u001b[0;31m         \u001b[0menqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m_close_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-1174b54ef6c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstocks_sequence_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstocks_sequence_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     use_multiprocessing=True, initial_epoch=0)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstocks_sequence_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStocksSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompanies_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   2218\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0menqueuer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m         \u001b[0menqueuer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfinished_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m_close_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_close_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    stocks_sequence_training, steps_per_epoch=1000, epochs=400, callbacks=callbacks, \n",
    "    validation_data = stocks_sequence_validation, validation_steps=100, workers=4, max_queue_size=20, verbose=1, \n",
    "    use_multiprocessing=True, initial_epoch=0)\n",
    "\n",
    "stocks_sequence_test = StocksSequence(stocks_data['test'], companies_data['test'], window_size, label_encoder, batch_size)\n",
    "\n",
    "model.evaluate_generator(stocks_sequence_test, 400, workers=2, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "02-dph-model-training.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
